'''
Trains a context-encoder network to perform image inpainting as described in 'Context Encoders: Feature Learning by
Inpainting' by Pathak et al. Note that 'generator' and 'autoencoder' are the same thing and used interchangeably.
'''


import tensorflow as tf
import model
import load_data
import os
import matplotlib.pyplot as plt
import time
import click

# Build models, define losses and optimizers
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)
MSE = tf.keras.losses.MeanSquaredError()
generator = model.build_autoencoder(True)
discriminator = model.build_discriminator()
generator_optimizer = tf.keras.optimizers.Adam(2e-2)
discriminator_optimizer = tf.keras.optimizers.Adam(2e-3)

'''
Defines the discriminator loss as the sum of
1. Binary cross entropy of its predictions of real centers against a tensor of all ones
2. Binary cross entropy of its predictions of generated centers against a tensor of all zeros

real_output: tensor of shape (batch_size, 1, 1, 1) - the discriminators predictions against real centers
fake_output: tensor of shape (batch_size, 1, 1, 1) - the discriminators predictions against centers generated by the
generator
'''


def discriminator_loss(real_output, fake_output):

    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss


'''
Defines the generator loss as the weighted sum of
1. Binary cross entropy of the discriminators predictions against a tensor of all ones (i.e. how well the generator
is tricking the discriminator.
2. Mean Squared error between the generated center and the real center


fake_output - tensor of shape (batch_size, 1, 1, 1) - the discriminators predictions against centers generated by the
generator
y_true - real center image array
y_pred - center image array generated by the autoencoder 
overlap - integer specifying the number of pixels to overlap the outside image with the center 
'''


def generator_loss(fake_output, y_true, y_pred, overlap, use_gpu, weight_l2=0.9, weight_adv=0.1):
    adv_loss = cross_entropy(tf.ones_like(fake_output), fake_output)
    if overlap != 0:
        if use_gpu:
            y_true_center = y_true[:, :, overlap:-overlap, overlap:-overlap]
            y_pred_center = y_pred[:, :, overlap:-overlap, overlap:-overlap]
            y_true_overlap_left = y_true[:, :, :overlap, :overlap]
            y_true_overlap_right = y_true[:, :, -overlap:, -overlap:]
            y_pred_overlap_left = y_pred[:, :, :overlap, :overlap]
            y_pred_overlap_right = y_pred[:, :, -overlap:, -overlap:]

        else:
            # if training is being done with an overlap, want 10x higher weight for loss in overlapped region
            y_true_center = y_true[:, overlap:-overlap, overlap:-overlap, :]
            y_pred_center = y_pred[:, overlap:-overlap, overlap:-overlap, :]
            y_true_overlap_left = y_true[:, :overlap, :overlap, :]
            y_true_overlap_right = y_true[:, -overlap:, -overlap:, :]
            y_pred_overlap_left = y_pred[:, :overlap, :overlap, :]
            y_pred_overlap_right = y_pred[:, -overlap:, -overlap:, :]

        center_loss = MSE(y_true_center, y_pred_center)
        overlap_loss = 10 * (MSE(y_true_overlap_left, y_pred_overlap_left)
                                                                    + MSE(y_true_overlap_right, y_pred_overlap_right))
        l2_loss = center_loss + overlap_loss
    else:

        l2_loss = MSE(y_true, y_pred)
    total_loss = weight_adv*adv_loss + weight_l2*l2_loss
    return total_loss


'''
One forward step and, if training=True, one pass of backpropegation for both the generator and discriminator.
The tf.function decorator means that this function is 'compiled' into a tensorflow graph a la tensorflow 1.x 
to increase speed. 

images - tensor containing images to train with
real_centers - tensor containing the real image centers 
overlap - integer specifying the number of pixels to overlap the outside image with the center 
training - if true, applied backprop to network, if false, just takes a forward pass. 
'''
@tf.function
def take_step(images, real_centers, overlap, use_gpu, training=True):

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_centers = generator(images, training=training)

        real_output = discriminator(real_centers, training=training)
        fake_output= discriminator(generated_centers, training=training)

        gen_loss = generator_loss(fake_output, real_centers, generated_centers, overlap, use_gpu)
        disc_loss = discriminator_loss(real_output, fake_output)

    if training:
        generator_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)
        discriminator_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

        generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))
        discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator.trainable_variables))
        print('took step')

    return gen_loss, disc_loss


def plot_loss(train_gen_loss, val_gen_loss, train_disc_loss, val_disc_loss):
    fig, (ax1, ax2) = plt.subplots(2, 1)
    ax1.plot(train_gen_loss, color='r', label='Training Loss')
    ax1.plot(val_gen_loss, color='b', label='Validation Loss')
    ax1.set_xlabel('Num. Epochs')
    ax1.set_ylabel('Loss')
    ax1.set_title('Generator Loss')
    ax1.legend()

    ax2.plot(train_disc_loss, color='r', label='Training Loss')
    ax2.plot(val_disc_loss, color='b', label='Validation Loss')
    ax2.set_xlabel('Num. Epochs')
    ax2.set_ylabel('Loss')
    ax2.set_title('Discriminator Loss')
    ax2.legend()
    plt.show()


'''
Trains model, saves a model checkpoint every 5 epochs, and plots a graph of training and validation loss for both
the autoencoder and discriminator after training. 

train_dataset - tf dataset object containing the training images and centers
val_dataset - tf dataset object contain the validation images and centers
overlap - integer specifying the number of pixels to overlap the outside image with the center 
'''


def train(train_dataset, val_dataset, epochs, overlap, use_gpu):

    checkpoint_dir = './training_checkpoints'
    checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                     discriminator_optimizer=discriminator_optimizer,
                                     generator=generator,
                                     discriminator=discriminator)
    list_train_gen_loss = []
    list_train_disc_loss = []
    list_val_gen_loss = []
    list_val_disc_loss = []
    for epoch in range(epochs):
        start = time.time()
        train_gen_loss = 0
        train_disc_loss = 0
        val_gen_loss = 0
        val_disc_loss = 0
        count = 0
        for image_batch, center_batch in train_dataset:
            gen_loss, disc_loss = take_step(image_batch, center_batch, overlap, use_gpu)
            train_gen_loss += gen_loss
            train_disc_loss += disc_loss

        for image_batch, center_batch in val_dataset:
            gen_loss, disc_loss = take_step(image_batch, center_batch, overlap, use_gpu, training=False)
            val_gen_loss += gen_loss
            val_disc_loss += disc_loss

        if (epoch + 1) % 5 == 0:
            checkpoint.save(file_prefix=checkpoint_prefix)
            test_image = image_batch[0:1, :, :, :]
            gen_center = generator(test_image, training=False)[0, :, :, :]
            test_image = test_image[0, :, :, :]
            test_center = center_batch[0, :, :, :]
            gen_center = (gen_center + 1) / 2
            test_image = (test_image + 1) / 2
            test_center = (test_center + 1) / 2
            plt.imshow(test_image)
            plt.title('Image. Epoch {}'.format(epoch))
            plt.savefig('Image. Epoch {}'.format(epoch))
            plt.show()
            plt.imshow(test_center)
            plt.title('Center. Epoch {}'.format(epoch))
            plt.savefig('Center. Epoch {}'.format(epoch))
            plt.show()
            plt.imshow(gen_center)
            plt.title('Generated Center. Epoch: {}'.format(epoch))
            plt.savefig('Generated Center. Epoch: {}'.format(epoch))
            plt.show()

        list_train_gen_loss.append(train_gen_loss)
        list_train_disc_loss.append(train_disc_loss)
        list_val_gen_loss.append(val_gen_loss)
        list_val_disc_loss.append(val_disc_loss)

        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))
        print('Generator - Training loss {} --- Validation loss {}'.format(train_gen_loss, val_gen_loss))
        print('Discriminator - Training loss {} --- Validation loss {} \n'.format(train_disc_loss, val_disc_loss))

    plot_loss(list_train_gen_loss, list_val_gen_loss, list_train_disc_loss, list_val_disc_loss)


@click.command()
@click.argument('train_data_path', type=click.Path(exists=True, readable=True))
@click.argument('val_data_path', type=click.Path(exists=True))
@click.option('--overlap', default=7, help='Size of overlap (in pixels) the predicted image in the real image')
@click.option('--batch_size', default=64)
@click.option('--use_gpu/--no_gpu', default=False)
@click.option('--epochs', default=50)
def main(train_data_path, val_data_path, overlap, batch_size, use_gpu, epochs):
    train_dataset = load_data.load_h5_to_dataset(train_data_path, overlap)
    train_dataset = train_dataset.batch(batch_size)

    val_dataset = load_data.load_h5_to_dataset(val_data_path, overlap)
    val_dataset = val_dataset.batch(batch_size)
    if use_gpu:
        gpu = input('Choose GPU to use:')
        with tf.device('/GPU:{}'.format(gpu)):
            train(train_dataset, val_dataset, epochs, overlap, use_gpu)
    else:
        train(train_dataset, val_dataset, epochs, overlap, use_gpu)


if __name__ == '__main__':
    main()
