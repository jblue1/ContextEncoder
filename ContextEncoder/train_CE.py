"""
Trains a context-encoder network to perform image inpainting as described in 'Context Encoders: Feature Learning by
Inpainting' by Pathak et al. Note that 'generator' and 'autoencoder' are the same thing and the terms used
interchangeably.

Notes:
- Data format of images changed depending on whether or not a gpu is being used. For an explanation, see 'Data Formats'
in https://www.tensorflow.org/guide/performance/overview
"""

import tensorflow as tf
import CE_model
import load_data
import os
import matplotlib.pyplot as plt
import time
import click
from datetime import date
import pandas as pd
from contextlib import redirect_stdout

# Build models, define losses and optimizers
cross_entropy = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,
                                                   from_logits=True)
MAE = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)


def discriminator_loss(real_output, fake_output):
    """
    Defines the discriminator loss as the sum of
    1. Binary cross entropy of its predictions of real centers against a tensor of all ones
    2. Binary cross entropy of its predictions of generated centers against a tensor of all zeros

    real_output: tensor of shape (batch_size, 1, 1, 1) - the discriminators predictions against real centers
    fake_output: tensor of shape (batch_size, 1, 1, 1) - the discriminators predictions against centers generated by the
    generator
    """

    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss


def generator_loss(fake_output, y_true, y_pred, weight_l2=0.9, weight_adv=0.1, use_adv=True):
    """
    Defines the generator loss as the weighted sum of
    1. Binary cross entropy of the discriminators predictions against a tensor of all ones (i.e. how well the generator
    is tricking the discriminator.
    2. Mean Squared error between the generated center and the real center

    fake_output: tensor of shape (batch_size, 1, 1, 1) - the discriminators predictions against centers generated by the
    generator
    y_true: tensor - real center image array
    y_pred: tensor - center image array generated by the autoencoder
    et al.
    """
    adv_loss = cross_entropy(tf.ones_like(fake_output), fake_output)
    l2_loss = MAE(y_true, y_pred)
    if use_adv:
        total_loss = weight_l2 * l2_loss + weight_adv * adv_loss
    else:
        total_loss = l2_loss
    return total_loss


@tf.function
def take_step(broken_images, images, generator, discriminator, use_gpu, generator_optimizer,
              discriminator_optimizer):
    """
    One forward step and, if training=True, one pass of backpropegation for both the generator and discriminator.
    The tf.function decorator means that this function is 'compiled' into a tensorflow graph a la tensorflow 1.x
    to increase speed.

    images: tensor - images to train with
    real_centers: tensor - real image centers
    """

    # 'fDx' in paper, train the discriminator
    with tf.GradientTape() as disc_tape:
        real_output = discriminator(images, training=True)
        generated_images = generator(broken_images, training=False)
        if use_gpu:
            fake_output = discriminator(generated_images, training=True)
        else:
            fake_output = discriminator(generated_images, training=True)
        disc_loss = discriminator_loss(real_output, fake_output)

    discriminator_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)
    discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator.trainable_variables))


    # 'fGx' in paper, train the generator

    with tf.GradientTape() as gen_tape:
        generated_images = generator(broken_images, training=True)
        if use_gpu:
            fake_output = discriminator(generated_images, training=False)
        else:
            fake_output = discriminator(generated_images, training=False)
        gen_loss = generator_loss(fake_output, images, generated_images, use_adv=False)

    generator_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)
    generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))

    return gen_loss, disc_loss


@tf.function
def calc_losses(image_contexts, images, use_gpu, generator, discriminator):
    """
    Calculates losses without training
    """
    generated_images = generator(image_contexts, training=False)
    real_output = discriminator(images, training=False)
    if use_gpu:
        fake_output = discriminator(generated_images, training=True)
    else:
        fake_output = discriminator(generated_images, training=True)

    disc_loss = discriminator_loss(real_output, fake_output)
    gen_loss = generator_loss(fake_output, images, generated_images, use_gpu, use_adv=False)
    l2_gen_loss = generator_loss(fake_output, images, generated_images, use_gpu, use_adv=False)

    return gen_loss, disc_loss, l2_gen_loss


def plot_loss(train_gen_loss, val_gen_loss, train_disc_loss, val_disc_loss, save_dir):
    """
    Saves a plot of the various losses over time. Takes in lists of the losses, and the directory
    to save the plot in.
    """
    fig, (ax1, ax2) = plt.subplots(2, 1)
    ax1.plot(train_gen_loss, color='r', label='Training Loss')
    ax1.plot(val_gen_loss, color='b', label='Validation Loss')
    ax1.set_xlabel('Num. Epochs')
    ax1.set_ylabel('Loss')
    ax1.set_title('Generator Loss')
    ax1.legend()

    ax2.plot(train_disc_loss, color='r', label='Training Loss')
    ax2.plot(val_disc_loss, color='b', label='Validation Loss')
    ax2.set_xlabel('Num. Epochs')
    ax2.set_ylabel('Loss')
    ax2.set_title('Discriminator Loss')
    ax2.legend()

    fig.subplots_adjust(hspace=0.45)
    filename = os.path.join(save_dir, 'Loss_history.png')
    plt.savefig(filename)
    plt.close()


def save_pictures(broken_images, images, epoch, use_gpu, save_dir, generator, prefix='',
                  num_pictures=5):
    """
    Saves a set of images, where each image contains the real broken spiral and the broken
    spiral generated by the model for comparison.

    image_batch: tensor - batch of input images
    center_batch: tensor - batch of broken spiral images
    epoch: int - current epoch
    save_dir: path - the directory to save the pictures in
    prefix: string - used to distinguish training and validation images in the filename
    num_pictures: int - number of images to save
    """
    # take data from [-1, 1] range to [0, 1] range for plotting
    gen_images = (generator(broken_images, training=False) + 1) / 2

    if len(broken_images) < num_pictures:
        num_pictures = 1

    if use_gpu:
        broken_images = tf.transpose(broken_images, (0, 2, 3, 1))
        gen_images = tf.transpose(gen_images, (0, 2, 3, 1))
    for i in range(num_pictures):
        filename = os.path.join(save_dir, prefix + '_epoch_{}_{}'.format(epoch, i) + '.png')
        fig, axs = plt.subplots(1, 3)
        fig.suptitle('Epoch: {}'.format(epoch))
        axs[0].imshow(broken_images[i, :, :, 0], cmap='Greys')
        axs[0].set_title('Broken Image')
        axs[1].imshow(gen_images[i, :, :, 0], cmap='Greys')
        axs[1].set_title('Generated Image')
        axs[2].imshow(images[i, 0, :, :], cmap='Greys')
        axs[2].set_title('Original Images')

        fig.subplots_adjust(wspace=.5)
        plt.savefig(filename)
        plt.close()


def train(train_dataset, val_dataset, epochs, use_gpu, lr, save_dir):
    """
    Trains model, saves a model checkpoint every 5 epochs, and plots a graph of training and validation loss for both
    the autoencoder and discriminator after training.
    """
    generator = CE_model.build_autoencoder(use_gpu)
    discriminator = CE_model.build_discriminator(use_gpu)
    filename = os.path.join(save_dir, 'modelsummary.txt')
    with open(filename, 'w') as f:
        with redirect_stdout(f):
            generator.summary()
            discriminator.summary()
    generator_optimizer = tf.keras.optimizers.Adam(lr * 10)
    discriminator_optimizer = tf.keras.optimizers.Adam(lr)
    checkpoint_dir = os.path.join(save_dir, 'training_checkpoints/')

    # save pictures using model in its initialized state for comparison
    broken_image, image = next(iter(train_dataset))
    if use_gpu:
        image = tf.transpose(image, (0, 3, 1, 2))
        broken_image = tf.transpose(broken_image, (0, 3, 1, 2))
    save_pictures(broken_image[0:1, :, :, :], image[0:1, :, :, :], 0, use_gpu, save_dir, generator,
                  prefix='init')

    list_train_gen_loss = []
    list_train_disc_loss = []
    list_val_gen_loss = []
    list_val_disc_loss = []
    list_l2_val_gen_loss = []
    for epoch in range(epochs):
        start = time.time()
        train_gen_loss = 0
        train_disc_loss = 0
        val_gen_loss = 0
        val_disc_loss = 0
        val_l2_gen_loss = 0
        count_train = 0
        count_val = 0
        for broken_image_batch, image_batch in train_dataset:
            # if using gpu need to transpose tensor to channels first
            if use_gpu:
                broken_image_batch = tf.transpose(broken_image_batch, (0, 3, 1, 2))
                image_batch = tf.transpose(image_batch, (0, 3, 1, 2))
            gen_loss, disc_loss = take_step(broken_image_batch,
                                            image_batch,
                                            generator,
                                            discriminator,
                                            use_gpu,
                                            generator_optimizer,
                                            discriminator_optimizer)
            train_gen_loss += gen_loss
            train_disc_loss += disc_loss
            count_train += 1
        # every 5th epoch (and the first) save training images for comparison
        if (epoch + 1) % 5 == 0 or epoch == 0:
            save_pictures(broken_image_batch, image_batch, epoch + 1, use_gpu, save_dir, generator,
                          prefix='train')
        for broken_image_batch, image_batch in val_dataset:
            if use_gpu:
                broken_image_batch = tf.transpose(broken_image_batch, (0, 3, 1, 2))
                image_batch = tf.transpose(image_batch, (0, 3, 1, 2))
            gen_loss, disc_loss, l2_gen_loss = calc_losses(broken_image_batch, image_batch,
                                                           use_gpu, generator, discriminator)
            val_gen_loss += gen_loss
            val_disc_loss += disc_loss
            val_l2_gen_loss += l2_gen_loss
            count_val += 1

        # every 5th epoch (and the first) save validation images for comparison and save model checkpoints
        if (epoch + 1) % 5 == 0 or epoch == 0:
            gen_filename = os.path.join(checkpoint_dir, 'gen' + '_' + str(epoch + 1))
            disc_filename = os.path.join(checkpoint_dir, 'disc' + '_' + str(epoch + 1))
            generator.save_weights(gen_filename)
            discriminator.save_weights(disc_filename)
            save_pictures(broken_image_batch, image_batch, epoch + 1, use_gpu, save_dir, generator,
                          prefix='val')
            if epoch == 0:
                # test that weight loading works
                gen_test = CE_model.build_autoencoder(use_gpu)
                gen_test.load_weights(gen_filename)
                print('WEIGHTS LOADED SUCCESSFULLY')
        # normalize loss by size of dataset
        train_gen_loss = train_gen_loss / count_train
        train_disc_loss = train_disc_loss / count_train
        val_gen_loss = val_gen_loss / count_val
        val_disc_loss = val_disc_loss / count_val
        val_l2_gen_loss = val_l2_gen_loss / count_val

        # .numpy() converts the tensors to np arrays, which in this case results in just floats.
        list_train_gen_loss.append(train_gen_loss.numpy())
        list_train_disc_loss.append(train_disc_loss.numpy())
        list_val_gen_loss.append(val_gen_loss.numpy())
        list_val_disc_loss.append(val_disc_loss.numpy())
        list_l2_val_gen_loss.append(val_l2_gen_loss.numpy())

        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))
        print('Generator - Training loss {} --- Validation loss {}'.format(train_gen_loss, val_gen_loss))
        print('Discriminator - Training loss {} --- Validation loss {} \n'.format(train_disc_loss, val_disc_loss))

    loss_df = pd.DataFrame({'Gen Training Loss': pd.Series(list_train_gen_loss),
                            'Gen Val Loss': pd.Series(list_val_gen_loss),
                            'Disc Training Loss': pd.Series(list_train_disc_loss),
                            'Disc Val Loss': pd.Series(list_val_disc_loss),
                            'Gen L2 Val Loss': pd.Series(list_l2_val_gen_loss)})
    plot_loss(list_train_gen_loss, list_val_gen_loss, list_train_disc_loss, list_val_disc_loss, save_dir)

    filename = os.path.join(save_dir, 'losses.csv')
    loss_df.to_csv(filename)


def write_info_file(save_dir, data_path, batch_size, use_gpu, epochs, lr,
                    run_number):
    """
    Writes a text file to the save directory with a summary of the hyper-parameters used for training
    """
    filename = os.path.join(save_dir, 'run_info.txt')
    info_list = ['ContextEncoder Hyper-parameters: Run {} \n'.format(run_number),
                 'Training data found at: {} \n'.format(data_path),
                 'Batch Size: {} \n'.format(batch_size),
                 'Use GPU: {} \n'.format(use_gpu),
                 'Epochs: {} \n'.format(epochs),
                 'Learning Rate: {} \n'.format(lr)]

    with open(filename, 'w') as f:
        f.writelines(info_list)


@click.command()
@click.argument('data_path', type=click.Path(exists=True, readable=True))
@click.argument('lut_path', type=click.Path(exists=True, readable=True))
@click.option('--batch_size', default=64)
@click.option('--use_gpu/--no_gpu', default=False)
@click.option('--epochs', default=100)
@click.option('--lr', default=2e-4, help='Learning rate for Adam optimizer')
@click.option('--run_number', default=1, help='ith run of the day')
def main(data_path, lut_path, batch_size, use_gpu, epochs, lr, run_number):
    #os.environ['CUDA_VISIBLE_DEVICES'] = ''
    print('Entered main')
    # construct directory to store images, model checkpoints etc.
    today = str(date.today())
    run_number = '_' + str(run_number)
    save_dir = './Run_' + today + run_number

    if os.path.exists(save_dir):
        ans = input(
            'The directory this run will write to already exists, would you like to overwrite it? ([y/n])')
        if ans == 'y':
            pass
        else:
            return
    else:
        os.makedirs(save_dir)
    write_info_file(save_dir, data_path, batch_size, use_gpu, epochs, lr,
                    run_number)
    print('Wrote info file')
    train_dataset, val_dataset = load_data.load_dataset(data_path, lut_path)
    print('Loaded Data')
    train_dataset = train_dataset.batch(batch_size)
    val_dataset = val_dataset.batch(batch_size)

    train(train_dataset, val_dataset, epochs, use_gpu, lr, save_dir)



if __name__ == '__main__':
    main()
