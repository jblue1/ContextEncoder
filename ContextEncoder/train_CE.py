"""
Trains a context-encoder network to perform image inpainting as described in 'Context Encoders: Feature Learning by
Inpainting' by Pathak et al. Note that 'generator' and 'autoencoder' are the same thing and the terms used
interchangeably.

Notes:
- Data format of images changed depending on whether or not a gpu is being used. For an explanation, see 'Data Formats'
in https://www.tensorflow.org/guide/performance/overview
"""

import tensorflow as tf
import CE_model
import load_data
import os
import matplotlib.pyplot as plt
import time
import click
from datetime import date
import pandas as pd
from contextlib import redirect_stdout
import numpy as np

# Build models, define losses and optimizers
cross_entropy = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,
                                                   from_logits=False, label_smoothing=0.1)
MSE = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)


def discriminator_loss(real_output, fake_output):
    """
    Defines the discriminator loss as the sum of
    1. Binary cross entropy of its predictions of real images against a tensor of all ones
    2. Binary cross entropy of its predictions of generated images against a tensor of all zeros
    :param tf.Tensor real_output: The discriminators predictions against real centers
    :param tf.Tensor fake_output: The discriminators predictions against centers generated by the
    generator
    :return tf.Tensor: Calculated loss
    """
    noise = np.zeros(real_output.shape)
    num_flips = int(0.05 * len(noise))
    noise[:num_flips].fill(1)
    np.random.shuffle(noise)
    comparison = tf.ones_like(real_output) - noise
    real_loss = cross_entropy(comparison, real_output)
    np.random.shuffle(noise)
    comparison = tf.zeros_like(fake_output) + noise
    fake_loss = cross_entropy(comparison, fake_output)
    total_loss = real_loss + fake_loss
    return total_loss


def generator_loss(fake_output, y_true, y_pred, weight_l2=0.9, weight_adv=0.1, use_adv=True):
    """
    Defines the generator loss as the weighted sum of
    1. Binary cross entropy of the discriminators predictions against a tensor of all ones (i.e. how well the generator
    is tricking the discriminator.
    2. Mean Squared error between the generated image and the real image
    :param tf.Tensor fake_output: The discriminator's predictions against images
    generated by the autoencoder
    :param tf.Tensor y_true: real image
    :param tf.Tensor y_pred: generated image
    :param float weight_l2: weight given to the L2 loss
    :param float weight_adv: weight given to the adversarial loss
    :param bool use_adv: Whether or not to use the adversarial loss
    :return tf.Tensor: Calculated loss
    """
    adv_loss = cross_entropy(tf.ones_like(fake_output), fake_output)
    l2_loss = MSE(y_true, y_pred)
    if use_adv:
        total_loss = weight_l2 * l2_loss + weight_adv * adv_loss
    else:
        total_loss = l2_loss
    return total_loss


#@tf.function
def take_step(broken_images, images, generator, discriminator, use_gpu, generator_optimizer,
              discriminator_optimizer, weight_adv, train_disc=True, train_gen=True):
    """
    One forward step and one pass of backpropegation for both the generator and discriminator.
    The tf.function decorator means that this function is 'compiled' into a tensorflow graph a la tensorflow 1.x
    to increase speed.
    :param tf.Tensor broken_images: Batch of broken image tensors
    :param tf.Tensor images: Batch of image tensors
    :param tf.keras.Model generator: Generator model object
    :param discriminator: Discriminator model object
    :param bool use_gpu: Whether or not a gpu is being used
    :param tf.keras.optomizers generator_optimizer: Keras optimizer object for generator
    :param tf.keras.optomizers discriminator_optimizer: Keras optimizer object for discriminator
    :param float weight_adv: weight of the adversarial loss used in the generator loss function
    :param bool train_disc: whether or not to train the discriminator
    :param bool train_gen: whether or not to train the generator
    :return tf.tensor: Generator and Discriminator loss
    """
    weight_l2 = 1 - weight_adv
    disc_loss = tf.constant(0)
    gen_loss = tf.constant(0)
    if train_disc:
        # 'fDx' in paper, train the discriminator
        with tf.GradientTape() as disc_tape:
            real_output = discriminator(images, training=True)
            generated_images = generator(broken_images, training=False)
            if use_gpu:
                fake_output = discriminator(generated_images, training=True)
            else:
                fake_output = discriminator(generated_images, training=True)
            disc_loss = discriminator_loss(real_output, fake_output)

        discriminator_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)
        discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator.trainable_variables))

    if train_gen:
        # 'fGx' in paper, train the generator
        with tf.GradientTape() as gen_tape:
            generated_images = generator(broken_images, training=True)
            if use_gpu:
                fake_output = discriminator(generated_images, training=False)
            else:
                fake_output = discriminator(generated_images, training=False)
            gen_loss = generator_loss(fake_output, images, generated_images, weight_l2, weight_adv, use_adv=False)

        generator_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)
        generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))

    return gen_loss, disc_loss


#@tf.function
def calc_losses(broken_images, images, use_gpu, generator, discriminator, weight_adv):
    """
    Calculates losses without training. All params are the same as take_step()
    """

    generated_images = generator(broken_images, training=False)
    real_output = discriminator(images, training=False)
    if use_gpu:
        fake_output = discriminator(generated_images, training=True)
    else:
        fake_output = discriminator(generated_images, training=True)

    disc_loss = discriminator_loss(real_output, fake_output)
    gen_loss = generator_loss(fake_output, images, generated_images, use_gpu, weight_adv, use_adv=False)
    l2_gen_loss = generator_loss(fake_output, images, generated_images, use_gpu, use_adv=False)

    return gen_loss, disc_loss, l2_gen_loss


def plot_loss(train_gen_loss, val_gen_loss, train_disc_loss, val_disc_loss, save_dir):
    """
    Saves a plot of the various losses over time. Takes in lists of the losses, and the directory
    to save the plot in.
    """
    fig, (ax1, ax2) = plt.subplots(2, 1)
    ax1.plot(train_gen_loss, color='r', label='Training Loss')
    ax1.plot(val_gen_loss, color='b', label='Validation Loss')
    ax1.set_xlabel('Num. Epochs')
    ax1.set_ylabel('Loss')
    ax1.set_title('Generator Loss')
    ax1.legend()

    ax2.plot(train_disc_loss, color='r', label='Training Loss')
    ax2.plot(val_disc_loss, color='b', label='Validation Loss')
    ax2.set_xlabel('Num. Epochs')
    ax2.set_ylabel('Loss')
    ax2.set_title('Discriminator Loss')
    ax2.legend()

    fig.subplots_adjust(hspace=0.45)
    filename = os.path.join(save_dir, 'Loss_history.png')
    plt.savefig(filename)
    plt.close()


def save_pictures(broken_images, images, epoch, use_gpu, save_dir, generator, discriminator, prefix='',
                  num_pictures=5):
    """
    Saves a set of images, where each image contains the real broken spiral and the broken
    spiral generated by the model for comparison.
    :param tf.Tensor broken_images: broken image tensors
    :param tf.Tensor images: image tensors
    :param int epoch: current epoch
    :param bool use_gpu: whether or not a gpu is being used
    :param str save_dir: path to the directory where the images will be saved
    :param tf.keras.Model generator: generator object
    :param tf.keras.Model discriminator: discriminator object
    :param str prefix: put it image title to identify kind of image (i.e. validation vs training)
    :param int num_pictures: number of pictures to save
    """
    generated_images = generator(broken_images, training=False)
    preds = discriminator(generated_images, training=False).numpy()

    if len(broken_images) < num_pictures:
        num_pictures = 1

    if use_gpu:
        broken_images = tf.transpose(broken_images, (0, 2, 3, 1))
        generated_images = tf.transpose(generated_images, (0, 2, 3, 1))
        images = tf.transpose(images, (0, 2, 3, 1))
    for i in range(num_pictures):
        filename = os.path.join(save_dir, prefix + '_epoch_{}_{}'.format(epoch, i) + '.png')
        fig, axs = plt.subplots(1, 3)
        fig.suptitle('Epoch: {}. Discriminator Prediction: {}'.format(epoch, preds[i]))
        axs[0].imshow(images[i, :, :, 0], cmap='Greys')
        axs[0].set_title('Original Images')
        axs[1].imshow(broken_images[i, :, :, 0], cmap='Greys')
        axs[1].set_title('Broken Image')
        axs[2].imshow(generated_images[i, :, :, 0], cmap='Greys')
        axs[2].set_title('Generated Image')

        fig.subplots_adjust(wspace=.5)
        plt.savefig(filename)
        plt.close()


def train(train_dataset, val_dataset, epochs, use_gpu, disc_lr, gen_lr, save_dir):
    """
    Trains model, saves a model checkpoint every 5 epochs, and plots a graph of training and validation loss for both
    the autoencoder and discriminator after training.
    :param tf.data.Dataset train_dataset: training dataset
    :param tf.data.Dataset val_dataset: validation dataset
    :param int epochs: number of epochs to train for
    :param bool use_gpu: whether or not to use a gpu
    :param float disc_lr: learning rate for discriminator optimizer
    :param float gen_lr: learning rate for generator optimizer
    :param str save_dir: path to directory to save images, training info file, and model weights to
    """
    generator = CE_model.build_autoencoder(use_gpu)
    discriminator = CE_model.build_discriminator(use_gpu)
    filename = os.path.join(save_dir, 'modelsummary.txt')
    with open(filename, 'w') as f:
        with redirect_stdout(f):
            generator.summary()
            discriminator.summary()
    generator_optimizer = tf.keras.optimizers.Adam(gen_lr)
    discriminator_optimizer = tf.keras.optimizers.Adam(disc_lr)
    checkpoint_dir = os.path.join(save_dir, 'training_checkpoints/')

    # save pictures using model in its initialized state for comparison
    broken_image, image = next(iter(train_dataset))
    if use_gpu:
        image = tf.transpose(image, (0, 3, 1, 2))
        broken_image = tf.transpose(broken_image, (0, 3, 1, 2))
    save_pictures(broken_image[0:1, :, :, :], image[0:1, :, :, :], 0, use_gpu, save_dir, generator, discriminator,
                  prefix='init')

    list_train_gen_loss = []
    list_train_disc_loss = []
    list_val_gen_loss = []
    list_val_disc_loss = []
    list_l2_val_gen_loss = []
    for epoch in range(epochs):
        if epoch < 10:
            weight_adv = 0.01
        elif epoch < 50:
            weight_adv = 0.1
        elif epoch < 100:
            weight_adv = 0.25
        else:
            weight_adv = 0.5
        start = time.time()
        train_gen_loss = 0
        train_disc_loss = 0
        val_gen_loss = 0
        val_disc_loss = 0
        val_l2_gen_loss = 0
        count_train = 0
        count_val = 0
        for broken_image_batch, image_batch in train_dataset:
            # if using gpu need to transpose tensor to channels first
            if use_gpu:
                broken_image_batch = tf.transpose(broken_image_batch, (0, 3, 1, 2))
                image_batch = tf.transpose(image_batch, (0, 3, 1, 2))
            gen_loss, disc_loss = take_step(broken_image_batch,
                                            image_batch,
                                            generator,
                                            discriminator,
                                            use_gpu,
                                            generator_optimizer,
                                            discriminator_optimizer,
                                            weight_adv)
            train_gen_loss += gen_loss
            train_disc_loss += disc_loss
            count_train += 1
        # every 5th epoch (and the first) save training images for comparison
        if (epoch + 1) % 5 == 0 or epoch == 0:
            save_pictures(broken_image_batch, image_batch, epoch + 1, use_gpu, save_dir, generator, discriminator,
                          prefix='train')
        for broken_image_batch, image_batch in val_dataset:
            if use_gpu:
                broken_image_batch = tf.transpose(broken_image_batch, (0, 3, 1, 2))
                image_batch = tf.transpose(image_batch, (0, 3, 1, 2))
            gen_loss, disc_loss, l2_gen_loss = calc_losses(broken_image_batch, image_batch,
                                                           use_gpu, generator, discriminator, weight_adv)
            val_gen_loss += gen_loss
            val_disc_loss += disc_loss
            val_l2_gen_loss += l2_gen_loss
            count_val += 1

        # every 5th epoch (and the first) save validation images for comparison and save model checkpoints
        if (epoch + 1) % 5 == 0 or epoch == 0:
            gen_filename = os.path.join(checkpoint_dir, 'gen' + '_' + str(epoch + 1))
            disc_filename = os.path.join(checkpoint_dir, 'disc' + '_' + str(epoch + 1))
            generator.save_weights(gen_filename)
            discriminator.save_weights(disc_filename)
            save_pictures(broken_image_batch, image_batch, epoch + 1, use_gpu, save_dir, generator, discriminator,
                          prefix='val')
            if epoch == 0:
                # test that weight loading works
                gen_test = CE_model.build_autoencoder(use_gpu)
                gen_test.load_weights(gen_filename)
                print('WEIGHTS LOADED SUCCESSFULLY')
        # normalize loss by size of dataset
        train_gen_loss = train_gen_loss / count_train
        train_disc_loss = train_disc_loss / count_train
        val_gen_loss = val_gen_loss / count_val
        val_disc_loss = val_disc_loss / count_val
        val_l2_gen_loss = val_l2_gen_loss / count_val

        # .numpy() converts the tensors to np arrays, which in this case results in just floats.
        list_train_gen_loss.append(train_gen_loss.numpy())
        list_train_disc_loss.append(train_disc_loss.numpy())
        list_val_gen_loss.append(val_gen_loss.numpy())
        list_val_disc_loss.append(val_disc_loss.numpy())
        list_l2_val_gen_loss.append(val_l2_gen_loss.numpy())

        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))
        print('Generator - Training loss {} --- Validation loss {}'.format(train_gen_loss, val_gen_loss))
        print('Discriminator - Training loss {} --- Validation loss {} \n'.format(train_disc_loss, val_disc_loss))

        loss_df = pd.DataFrame({'Gen Training Loss': pd.Series(list_train_gen_loss),
                                'Gen Val Loss': pd.Series(list_val_gen_loss),
                                'Disc Training Loss': pd.Series(list_train_disc_loss),
                                'Disc Val Loss': pd.Series(list_val_disc_loss),
                                'Gen L2 Val Loss': pd.Series(list_l2_val_gen_loss)})
        filename = os.path.join(save_dir, 'losses.csv')
        loss_df.to_csv(filename)
    plot_loss(list_train_gen_loss, list_val_gen_loss, list_train_disc_loss, list_val_disc_loss, save_dir)


def write_info_file(save_dir, data_path, batch_size, use_gpu, epochs, disc_lr, gen_lr,
                    run_number):
    """
    Writes a text file to the save directory with a summary of the hyper-parameters used for training
    :param str save_dir: path to directory to save the file to
    :param str data_path: path to .h5 data file
    :param int batch_size: size of batches used in training
    :param bool use_gpu: whether or not a gpu was used during training
    :param int epochs: number of epochs network was trained for
    :param float disc_lr: learning rate for the discriminator
    :param float gen_lr: learning rate for the generator
    :param str run_number: Run number of the day
    """
    filename = os.path.join(save_dir, 'run_info.txt')
    info_list = ['ContextEncoder Hyper-parameters: Run {} \n'.format(run_number),
                 'Training data found at: {} \n'.format(data_path),
                 'Batch Size: {} \n'.format(batch_size),
                 'Use GPU: {} \n'.format(use_gpu),
                 'Epochs: {} \n'.format(epochs),
                 'Discriminator Learning Rate: {} \n'.format(disc_lr),
                 'Generator Learning Rate: {} \n'.format(gen_lr)]

    with open(filename, 'w') as f:
        f.writelines(info_list)


@click.command()
@click.argument('data_path', type=click.Path(exists=True, readable=True))
@click.argument('lut_path', type=click.Path(exists=True, readable=True))
@click.argument('indices_path', type=click.Path(exists=True, readable=True))
@click.option('--num_events', default=-1, help='Number of events to train on')
@click.option('--batch_size', default=64)
@click.option('--use_gpu/--no_gpu', default=False)
@click.option('--epochs', default=100)
@click.option('--disc_lr', default=2e-4, help='Learning rate for discriminator')
@click.option('--gen_lr', default=2e-4, help='Learning rate for generator')
@click.option('--run_number', default=1, help='ith run of the day')
def main(data_path, lut_path, indices_path, num_events, batch_size, use_gpu, epochs, disc_lr, gen_lr, run_number):
    if not use_gpu:
        os.environ['CUDA_VISIBLE_DEVICES'] = ''
    print('Entered main')
    # construct directory to store images, model checkpoints etc.
    today = str(date.today())
    run_number = '_' + str(run_number)
    save_dir = './Run_' + today + run_number

    if os.path.exists(save_dir):
        ans = input(
            'The directory this run will write to already exists, would you like to overwrite it? ([y/n])')
        if ans == 'y':
            pass
        else:
            return
    else:
        os.makedirs(save_dir)
    write_info_file(save_dir, data_path, batch_size, use_gpu, epochs, disc_lr, gen_lr,
                    run_number)
    print('Wrote info file')
    train_dataset, val_dataset = load_data.load_dataset(data_path, lut_path, indices_path, num_events)
    print('Loaded Data')
    train_dataset = train_dataset.batch(batch_size)
    val_dataset = val_dataset.batch(batch_size)

    train(train_dataset, val_dataset, epochs, use_gpu, disc_lr, gen_lr, save_dir)


if __name__ == '__main__':
    main()
